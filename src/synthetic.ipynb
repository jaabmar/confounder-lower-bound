{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Large \\textbf{Deriving a lower bound for hidden confounding in obs studies (Part 1)}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook offers a tutorial on assessing and measuring hidden confounding in synthetic data, using methods from \"Hidden yet quantifiable: A lower bound for confounding strength using randomized trials\". Detailed information is in the accompanying paper.\n",
    "\n",
    "The core idea is comparing the average treatment effect (ATE) estimates from a randomized trial and an observational study through hypothesis testing. The approach uses sensitivity analysis-derived bounds as a measure of distance between these estimates. This distance represent a chosen confounding strength ($\\Gamma$); by evaluating increasing $\\Gamma$ values, we can establish a lower bound for the true confounding strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import bootstrap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from test_confounding.ate_bounds.ate_bounds import BootstrapSensitivityAnalysis\n",
    "from test_confounding.cate_bounds.cate_bounds import MultipleCATEBoundEstimators\n",
    "from test_confounding.cate_bounds.utils_cate_bounds import compute_bootstrap_variance\n",
    "from test_confounding.datasets import synthetic\n",
    "from test_confounding.utils_general import e_x_func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement our test, we need a randomized trial and an observational study that adhere to Assumptions 1, 2, and 3 outlined in the paper. Specifically, the conditional ATE should be transportable from the trial to the observational study, the trial must satisfy internal validity, and the support of the trial must be included within that of the observational study. The below code creates a dataset with these properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 20000 #obs study size\n",
    "n_rct = 5000 #randomized trial size\n",
    "true_conf = 6.0 #true conf. strengh, ie \\Gamma^* in the paper\n",
    "effective_conf = 1.0 #parameter to interpolate between adv prop score (1.0) and uncorrelated hidden confounder (0.0)\n",
    "seed = 42 #seed for reproducibility\n",
    "\n",
    "data = synthetic.Synthetic(\n",
    "        num_examples_obs =  n_obs,\n",
    "        num_examples_rct = n_rct,\n",
    "        gamma_star = true_conf,\n",
    "        effective_conf = effective_conf,\n",
    "        sigma_y = 0.01,\n",
    "        seed=seed,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper proposes two testing procedures, determined by the target population. Firstly, we consider the randomized trial as the target population. In this approach, we derive CATE sensitivity bounds from observational data, average them over the trial, and then compare this result with the ATE directly computed from the trial. For the CATE bounds, we use the BLearner.\n",
    "\n",
    "Next, we test the null hypothesis of \"sufficient confounding strength,\" implying that the chosen $\\Gamma$ is large enough to explain the discrepancy between the observational study and the trial. We conduct this test for increasing $\\Gamma$ until the null hypothesis is accepted, in order to avoid a multiple testing problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CATE estimators are now instantiated.\n",
      "All CATE bounds estimators are now trained. Elapsed time: 40.76 seconds\n"
     ]
    }
   ],
   "source": [
    "n_bootstrap = 50 #bootstrap samples\n",
    "user_conf = [1.0, 3.0, 5.0, 5.5, 6.0, 7.0] #conf strengths to be tested\n",
    "\n",
    "x_rct, t_rct, y_rct = (\n",
    "    data.rct.x,\n",
    "    data.rct.t,\n",
    "    data.rct.y,\n",
    ")\n",
    "\n",
    "x_obs, t_obs, y_obs = (\n",
    "    data.x,\n",
    "    data.t,\n",
    "    data.y,\n",
    ")\n",
    "\n",
    "ate = y_rct[t_rct == 1].mean() - y_rct[t_rct == 0].mean()\n",
    "ate_variance = compute_bootstrap_variance(Y=y_rct, T=t_rct, n_bootstraps=n_bootstrap, arm=None)\n",
    "\n",
    "bounds_estimator = MultipleCATEBoundEstimators(\n",
    "    gammas=user_conf, n_bootstrap=n_bootstrap\n",
    ")\n",
    "\n",
    "bounds_estimator.fit(x_obs=x_obs, t_obs=t_obs, y_obs=y_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_confounding.test import run_multiple_cate_hypothesis_test\n",
    "\n",
    "results_dict_cate = run_multiple_cate_hypothesis_test(bounds_estimator = bounds_estimator, ate = ate, ate_variance = ate_variance, alpha = 5.0, x_rct = x_rct, user_conf = user_conf, verbose = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now present the outcomes of the testing procedure. We identify $\\Gamma_{LB}=5.5$ as a lower bound for the true strength $\\Gamma^*=6.0$, indicating that our test is valid and yields reasonable power. It's worth noting that a finer discretisaion in the tested $\\Gamma$ values would be more beneficial in practical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "------------------------------\n",
      "Γ: 1.0\n",
      "  - Reject Null Hypothesis: Yes\n",
      "  - Test Statistic: -10.756724410509511\n",
      "------------------------------\n",
      "Γ: 3.0\n",
      "  - Reject Null Hypothesis: Yes\n",
      "  - Test Statistic: -5.2264810086448374\n",
      "------------------------------\n",
      "Γ: 5.0\n",
      "  - Reject Null Hypothesis: Yes\n",
      "  - Test Statistic: -1.976865212607717\n",
      "------------------------------\n",
      "Γ: 5.5\n",
      "  - Reject Null Hypothesis: No\n",
      "  - Test Statistic: -1.2038360113769537\n",
      "------------------------------\n",
      "Γ: 6.0\n",
      "  - Reject Null Hypothesis: No\n",
      "  - Test Statistic: N/A\n",
      "------------------------------\n",
      "Γ: 7.0\n",
      "  - Reject Null Hypothesis: No\n",
      "  - Test Statistic: N/A\n",
      "------------------------------\n",
      "Γ_{LB} (Lower Bound): 5.5\n"
     ]
    }
   ],
   "source": [
    "def display_gamma_info(gamma_dict, user_conf): \n",
    "    print(\"Test Results:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for gamma in user_conf:\n",
    "        if gamma in gamma_dict:\n",
    "            value = gamma_dict[gamma]\n",
    "            reject = \"Yes\" if value['reject'] else \"No\"\n",
    "            test_statistic = value['test_statistic']\n",
    "        else:\n",
    "            # If gamma is not in gamma_dict, assume hypothesis is accepted\n",
    "            reject = \"No\"\n",
    "            test_statistic = \"N/A\"\n",
    "\n",
    "        print(f\"Γ: {gamma}\")\n",
    "        print(f\"  - Reject Null Hypothesis: {reject}\")\n",
    "        print(f\"  - Test Statistic: {test_statistic}\")\n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    gamma_effective = gamma_dict.get('gamma_effective', 'Not available')\n",
    "    print(f\"Γ_{{LB}} (Lower Bound): {gamma_effective}\")\n",
    "\n",
    "\n",
    "display_gamma_info(results_dict_cate, user_conf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we apply the same methodology but with the observational study as the target population. Specifically, we focus only on the region where the trial and the study overlap, achieved by performing trimming. Here, we estimate ATE sensitivity bounds on the observational study using the QB estimator and compare it to the (weighted) ATE estimated in the trial.\n",
    "\n",
    "We observe that the test is still valid and also identifies $\\Gamma_{LB}=5.5$ as the lower bound for the true confounding strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile functions are now trained for QB. Starting bootstrap.\n",
      "Elapsed time for 50 bootstrap samples: 292.27 seconds\n"
     ]
    }
   ],
   "source": [
    "x = np.concatenate((data.rct.x.reshape(-1), data.x.reshape(-1))).reshape(-1, 1)\n",
    "s = np.concatenate((np.ones(data.rct.x.size), np.zeros(data.x.size)))\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=seed)\n",
    "clf.fit(x, s)\n",
    "pi_s = clf.predict_proba(x)[:, 1]\n",
    "O_idx = pi_s > 0.001\n",
    "\n",
    "x_obs, t_obs, y_obs = (\n",
    "    data.x[O_idx[n_rct :]],\n",
    "    data.t[O_idx[n_rct :]],\n",
    "    data.y[O_idx[n_rct :]],\n",
    ")\n",
    "x_rct, t_rct, y_rct = (\n",
    "    data.rct.x[O_idx[: n_rct]],\n",
    "    data.rct.t[O_idx[: n_rct]],\n",
    "    data.rct.y[O_idx[: n_rct]],\n",
    ")\n",
    "\n",
    "mask = np.logical_and(O_idx, s)  \n",
    "rct_to_obs_ratio = s[O_idx].sum() / (s[O_idx].size - s[O_idx].sum())\n",
    "ys = 2 * (y_rct * t_rct - y_rct * (1 - t_rct)) * (1 - pi_s[mask]) / pi_s[mask]\n",
    "bootstrap_rct = bootstrap((ys,), np.mean, n_resamples=n_bootstrap, axis=0)\n",
    "std_rct = bootstrap_rct.standard_error\n",
    "var_rct = np.power(std_rct, 2) * (rct_to_obs_ratio**2)\n",
    "mean_rct = rct_to_obs_ratio * ys.mean()\n",
    "bootstrap_sa = BootstrapSensitivityAnalysis(sa_name=\"QB\", inputs=x_obs, treatment=t_obs, outcome=y_obs, gammas=user_conf, seed=seed, e_x_func=e_x_func)\n",
    "bounds_dist = bootstrap_sa.bootstrap(num_samples=n_bootstrap, fast_quantile=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_confounding.test import run_multiple_ate_hypothesis_test\n",
    "\n",
    "results_dict_ate = run_multiple_ate_hypothesis_test(mean_rct = mean_rct, var_rct = var_rct, bounds_dist = bounds_dist, alpha = 5.0, user_conf = user_conf, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "------------------------------\n",
      "Γ: 1.0\n",
      "  - Reject Null Hypothesis: Yes\n",
      "  - Test Statistic: -12.92638469497381\n",
      "------------------------------\n",
      "Γ: 3.0\n",
      "  - Reject Null Hypothesis: Yes\n",
      "  - Test Statistic: -5.849617052695993\n",
      "------------------------------\n",
      "Γ: 5.0\n",
      "  - Reject Null Hypothesis: Yes\n",
      "  - Test Statistic: -1.98155584903497\n",
      "------------------------------\n",
      "Γ: 5.5\n",
      "  - Reject Null Hypothesis: No\n",
      "  - Test Statistic: -1.1879252583555024\n",
      "------------------------------\n",
      "Γ: 6.0\n",
      "  - Reject Null Hypothesis: No\n",
      "  - Test Statistic: N/A\n",
      "------------------------------\n",
      "Γ: 7.0\n",
      "  - Reject Null Hypothesis: No\n",
      "  - Test Statistic: N/A\n",
      "------------------------------\n",
      "Γ_{LB} (Lower Bound): 5.5\n"
     ]
    }
   ],
   "source": [
    "display_gamma_info(results_dict_ate, user_conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf21b1a4de40f179e989ee5efafd4a121b190d1b06ef457fbf4e132f1ff3fa9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
