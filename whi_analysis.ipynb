{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets.whi import DataModuleWHI\n",
    "from scipy.stats import bootstrap\n",
    "import numpy as np\n",
    "from ATE.ate_bounds import BootstrapSensitivityAnalysis\n",
    "\n",
    "from ATE.methods.QB import QBSensitivityAnalysis\n",
    "from ATE.methods.ZSB import ZSBSensitivityAnalysis\n",
    "from test import  run_multiple_ate_hypothesis_test\n",
    "from model import Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctos = pd.read_csv('datasets/whi_processed/ctos_table.csv')\n",
    "df_ctos['TOTPTIME'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the WHI dataset, selecting patients that started treatment at most 2 years ago. This is to make sure that transportability of CATE holds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "whi = DataModuleWHI(root='datasets/')\n",
    "whi.process_whi()\n",
    "df_rct, df_obs, df_merged = whi.get_datasets()\n",
    "df_obs = df_obs[0]\n",
    "df_obs = df_merged[(df_ctos['OS']==1) & (df_ctos['TOTPTIME']<=20)]\n",
    "df_merged = df_merged[ (df_ctos['OS']==0) | (df_ctos['TOTPTIME'] <=20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first look at coronary heart disease, here from previous studies we expect small amount of confounding. We choose as covariates the standard ones from the epidemiology studies on WHI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'CHD_E'\n",
    "#covariates = ['AGE', 'ETHNIC_Black or African-American', 'ETHNIC_Hispanic/Latino','ETHNIC_White (not of Hispanic origin)', 'BMI',\n",
    "#'EDUC_x_College graduate or Baccalaureate Degree', 'EDUC_x_Didn\\'t go to school', 'EDUC_x_Doctoral Degree (Ph.D,M.D.,J.D.,etc.)', 'EDUC_x_Grade school (1-4 years)',\n",
    "#'EDUC_x_Grade school (5-8 years)','EDUC_x_Some high school (9-11 years)', \n",
    "#'EDUC_x_Some post-graduate or professional', 'EDUC_x_Vocational or training school', 'SMOKING_Never Smoked','SMOKING_Past Smoker','SMOKING_Current Smoker',\n",
    "#'ETHNIC_American Indian or Alaskan Native','ETHNIC_Asian or Pacific Islander']\n",
    "\n",
    "covariates = ['AGE','ETHNIC_White (not of Hispanic origin)', \n",
    "'BMI','SMOKING_Past Smoker','SMOKING_Current Smoker','EDUC_x_College graduate or Baccalaureate Degree',\n",
    "'EDUC_x_Some post-graduate or professional', 'MENO', 'PHYSFUN']\n",
    "\n",
    "\n",
    "others = [outcome,'HRTARM']\n",
    "df_rct = df_rct[covariates + others]\n",
    "df_obs = df_obs[covariates + others]\n",
    "df_merged_covariates = df_merged[covariates]\n",
    "df_merged = df_merged[covariates + others + ['OS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCT suggest increased risk of CHD after taking HRT, in agreement with the epid. studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RCT) E[Y(1)]: 0.019868328238890197, E[Y(0)]: 0.015921994569242162, ATE: 0.003946333669648035\n"
     ]
    }
   ],
   "source": [
    "y1 = df_rct[df_rct['HRTARM'] == 1][outcome].mean()\n",
    "y0 = df_rct[df_rct['HRTARM'] == 0][outcome].mean()\n",
    "print(f\"(RCT) E[Y(1)]: {y1}, E[Y(0)]: {y0}, ATE: {y1-y0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rct = df_rct[outcome].to_numpy()\n",
    "y_obs = df_obs[outcome].to_numpy()\n",
    "x_rct = df_rct.iloc[:,:-2].to_numpy()\n",
    "x_obs = df_obs.iloc[:,:-2].to_numpy()\n",
    "t_obs = df_obs['HRTARM'].to_numpy()\n",
    "t_rct= df_rct['HRTARM'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OBS) E[Y|T=1]: 0.0370562780805697,  E[Y|T=0]: 0.04455145931501153, ATE: -0.007495181234441831\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(x_obs, t_obs)\n",
    "e_x=clf.predict_proba(x_obs)[:, 1] \n",
    "\n",
    "w1 = 1/e_x\n",
    "w0 = 1/(1-e_x)\n",
    "y1 = (y_obs*t_obs*w1).sum()/(t_obs*w1).sum()\n",
    "y0 = (y_obs*(1-t_obs)*w0).sum()/((1-t_obs)*w0).sum()\n",
    "print(f\"(OBS) E[Y|T=1]: {y1},  E[Y|T=0]: {y0}, ATE: {y1-y0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know proceed with the ATE test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_merged_covariates.to_numpy()\n",
    "s = df_merged['OS'].to_numpy()\n",
    "\n",
    "alpha_trim= 0.001\n",
    "clf_pi =  RandomForestClassifier(max_depth=15, random_state=0)\n",
    "#clf_pi = LogisticRegression()\n",
    "clf_pi.fit(x, s)\n",
    "pi_s = 1-clf_pi.predict_proba(x)[:,1]\n",
    "O_idx =  np.logical_and(pi_s > alpha_trim, pi_s < 1-alpha_trim)\n",
    "df_overlap = df_merged[O_idx]\n",
    "df_overlap_obs = df_overlap[df_overlap['OS']==1] \n",
    "df_overlap_rct = df_overlap[df_overlap['OS']==0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rct = df_overlap_rct[outcome].to_numpy()\n",
    "y_obs = df_overlap_obs[outcome].to_numpy()\n",
    "\n",
    "x_rct = df_overlap_rct.iloc[:,:-3].to_numpy()\n",
    "x_obs = df_overlap_obs.iloc[:,:-3].to_numpy()\n",
    "t_obs = df_overlap_obs['HRTARM'].to_numpy()\n",
    "t_rct= df_overlap_rct['HRTARM'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_rct:0.0029141646715864235\n"
     ]
    }
   ],
   "source": [
    "mask = np.logical_and(O_idx, 1-s)  # \\pi_S over RCT and \\OO\n",
    "rct_to_obs_ratio = (s[O_idx].sum() / (s[O_idx].size - s[O_idx].sum()))**-1\n",
    "ys = 2 * (y_rct * t_rct - y_rct * (1 - t_rct)) * (1 - pi_s[mask]) / pi_s[mask]\n",
    "bootstrap_rct = bootstrap((ys,), np.mean, n_resamples=500, axis=0)\n",
    "std_rct = bootstrap_rct.standard_error\n",
    "var_rct = np.power(std_rct, 2) * (rct_to_obs_ratio**2)\n",
    "mean_rct = rct_to_obs_ratio * ys.mean()\n",
    "print(f'mean_rct:{mean_rct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OBS) E[Y|T=1]: 0.0370562780805697,  E[Y|T=0]: 0.04455145931501153, ATE: -0.007495181234441831\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression( )\n",
    "clf.fit(x_obs, t_obs)\n",
    "e_x=clf.predict_proba(x_obs)[:, 1] \n",
    "\n",
    "w1 = 1/e_x\n",
    "w0 = 1/(1-e_x)\n",
    "y1 = (y_obs*t_obs*w1).sum()/(t_obs*w1).sum()\n",
    "y0 = (y_obs*(1-t_obs)*w0).sum()/((1-t_obs)*w0).sum()\n",
    "print(f\"(OBS) E[Y|T=1]: {y1},  E[Y|T=0]: {y0}, ATE: {y1-y0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CATE estimators are now instantiated.\n",
      "All CATE bounds estimators are now trained. Elapsed time: 3.42 seconds\n"
     ]
    }
   ],
   "source": [
    "from CATE.utils_cate_test import compute_bootstrap_variance\n",
    "from CATE.cate_bounds import  MultipleCATEBoundEstimators\n",
    "from test import run_multiple_cate_hypothesis_test, run_multiple_ate_hypothesis_test, construct_cate_test_statistic\n",
    "\n",
    "ate = y_rct[t_rct == 1].mean() - y_rct[t_rct == 0].mean()\n",
    "ate_variance = compute_bootstrap_variance(y_rct, t_rct, 100, arm=None)\n",
    "\n",
    "bounds_estimator = MultipleCATEBoundEstimators(gammas=[1.3], n_bootstrap=30, binary=True, mu=LogisticRegression())\n",
    "\n",
    "bounds_estimator.fit(x_obs, t_obs, y_obs, sample_weight=False)\n",
    "dictionary_bounds_estimators = bounds_estimator.dict_bound_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1.3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/pdebartol/Projects/robust-cate/whi_analysis.ipynb Cell 18\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pdebartol/Projects/robust-cate/whi_analysis.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ate_lb, ate_ub \u001b[39m=\u001b[39m dictionary_bounds_estimators[\u001b[39mstr\u001b[39;49m(\u001b[39m1.3\u001b[39;49m)]\u001b[39m.\u001b[39mcompute_ate_bounds(x_obs)\n",
      "\u001b[0;31mKeyError\u001b[0m: '1.3'"
     ]
    }
   ],
   "source": [
    "ate_lb, ate_ub = dictionary_bounds_estimators[str(1.3)].compute_ate_bounds(x_obs)\n",
    "#var_lb, var_ub, quantile_lb, quantile_ub = dictionary_bounds_estimators[str(1.2)].estimate_bootstrap_variances(x_obs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2364050129648962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ate_ub-mean_rct)/(np.sqrt(var_rct+var_ub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome functions are now trained for QB. Starting bootstrap.\n",
      "Elapsed time for 50 bootstrap samples: 9.38 seconds\n"
     ]
    }
   ],
   "source": [
    "bootstrap_sa = BootstrapSensitivityAnalysis(\"QB\", x_obs, t_obs, y_obs, [1.3], e_x_func=None, binary=True)\n",
    "bounds_dist = bootstrap_sa.bootstrap(num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0068641361046064085"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ate_ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005487749541212863"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bounds_dist['1.4'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "mu1 = LogisticRegression(\n",
    "                    \n",
    "                )\n",
    "mu0 =  LogisticRegression(\n",
    "                   \n",
    "                )\n",
    "mu1.fit(x_obs[t_obs==1], y_obs[t_obs==1])\n",
    "mu0.fit(x_obs[t_obs==0], y_obs[t_obs==0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.006183868873960963"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mu1.predict_proba(x_obs)[:,1] - mu0.predict_proba(x_obs)[:,1] ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datatable38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
